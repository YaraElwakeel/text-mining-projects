{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission - Exercises sheet 1\n",
    "MA-INF 4236 - Advanced Methods for Text Mining, So24<br>\n",
    "Yara Elwakeel 50135730<br>\n",
    "Aksa Aksa 50146305<br>\n",
    "May 15, 2024<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 concpts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ### Sentence tokenization\n",
    "    A tokenizer segments the text into sentences. As once a text is divided into sentences, \n",
    "    it becomes easier to analyze the grammatical structure and syntax of each sentence.\n",
    "    It identifies the boundaries of sentences in a given text. Typically, sentences end with punctuation marks (eg, \"?\", \",\", \".\") as they are keys of sentence boundaries.\n",
    "    This is crucial for tasks such as grammatical analysis and dependency parsing. Additionally, it improves efficiency as Working with individual sentences rather than large blocks of text enables a more focused analysis, as each sentence can be processed separately.\n",
    "    \n",
    "2. ### Word Tokenization \n",
    "    It decomposes each text string into a sequence of words (technically tokens) for computational analysis. Where it allows for further analysis and manipulation of the text, such as lemmatization, stemming, or part-of-speech tagging.\n",
    "    in addition, tokenization is often the first step in preparing data for training. It ensures that the data is in a structured format suitable for modeling.\n",
    "    NLTK has module word_tokenize() which uses a default tokenizer that can handle different types of punctuation and language nuances to correctly split the text into words.\n",
    "    \n",
    "3. ### Part-of-speech (POS) tagging\n",
    "    Part of Speech (POS) Tagging aims at assigning each word of a text the proper syntactic tag in its context of appearance. also called grammatical tagging, it can be seen as a grammatical classification that includes verbs, adjectives, adverbs, nouns, etc. it's an essential step in many NLP tasks as it provides grammatical structure and syntactic information about the text. as a word meaning is dependent on it's POS and it's context. especially in machine translation, information retrieval , named entity recognition as it helps identify PROPN and named entities and Text-to-speech as it also includes cues for correct pronunciation and inflection.<br>\n",
    "    Several POS tagging approaches have been proposed to automatically tag words with part-of-speech tags in a sentence. The most familiar approaches are rule-based where uses hand-crafted rules to assign tags to words in a sentence, artificial neural network Uses neural network architectures such as RNN to assign POS tags ,a stochastic is a statistical method that uses probability and statistics to determine the most likely POS tag for a given word based on its context(e.g hidden markov models(HMM) or conditional random fields(CRF) ) . and a hybrid approach which combines different methodologies, such as rule-based and stochastic methods, to take advantage of the strengths of each method and improve performance.[2]\n",
    "\n",
    "    \n",
    "4. ### Lemmetization \n",
    "    The goal is to normalize different inflected forms of a word  Lemmatization is a natural language processing (NLP) technique that groups words based on their lemma, or base form, by removing inflectional morphemes. where an inflectional morpheme is a bound morpheme added to a word to indicate grammatical properties. In addition, Lemmatization takes into account the part of speech (POS) of a word, such as noun, verb, adjective, or adverb, so that they can be analyzed or compared more easily. In Python, the WordNetLemmatizer class from the Natural Language Toolkit (NLTK) leverages the WordNet lexical database to lemmatize each word in an input sentence according to its POS tag.The lemmatizer can also be applied to individual words, mapping them to a single, most common lemma, or providing different lemmas based on the specified POS tag. For instance, the word \"leaves\" can have the lemma \"leave\" (verb) or \"leaf\" (noun), Lemmatization is especially useful for parsing languages like Turkish and Arabic, where grammatical relationships such as subject, verb, and object are indicated by changes in the words themselves. . [1, p. 526]\n",
    "5. ### Stop words removal\n",
    "    Stop words refer to the words that do not distinguish one text document from another in the corpus Examples include \"the\" and \"or\" because they are extremely common across documents, leading to little distinction among each document.so that text models can focus on the distinctive meaningful words that carry more information thus improving the model's performance , these non distinctive words with high number of occurrences can increase the data dimensionalty which may distort the results of a machine learning algorithm .\n",
    "    you can use a predefined list of stop words from libraries such as NLTK which possess a list of 127 English stop words, SpaCy , or even create your own custom list based on the used language and applied problem . [1, p. 523]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.word_tokenize()<br> \n",
    "operates by breaking down a given text into individual tokens, where each token represents either a word or a punctuation mark. It uses language-specific rules and patterns to identify boundaries between words and punctuation marks, segmenting the input text into a list of tokens\n",
    "\n",
    "nltk.sent_tokenize()<br> \n",
    "The sent_tokenize function uses an instance of PunktSentenceTokenizer from the nltk.tokenize.punkt module, which is pretrained and thus very well knows to \n",
    "identify the boundaries of sentences in a given text using what characters and punctuation.  \n",
    "\n",
    "nlkt.WordNetLemmatizaer()<br>\n",
    "The WordNetLemmatizer uses the WordNet lexical database to find the lemma of a word. WordNet contains a large corpus of words and their relationships, including synonyms, hypernyms, hyponyms, and other linguistic information.\n",
    "\n",
    "nltk.corpus.stopwords()<br>\n",
    "is a function provided by the NLTK library that returns a set of commonly used stopwords for the English language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yarae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import *\n",
    "download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nltk', 'leading', 'platform', '.'], ['building', 'python', 'program', 'work', 'human', 'language', 'data', '.'], ['provides', 'easy-to-use', 'interface', '50', 'corpus', 'lexical', 'resource', 'wordnet', ',', 'along', 'suite', 'text', 'processing', 'library', 'classification', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'semantic', 'reasoning', ',', 'wrapper', 'industrial-strength', 'nlp', 'library', '.']]\n"
     ]
    }
   ],
   "source": [
    "def process_paragraph(paragraph):\n",
    "    # split the paragraph into sentences. \n",
    "    split_sent = tokenize.sent_tokenize(paragraph)\n",
    "    \n",
    "\n",
    "    # initialize wordNet lemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    # get english stopwords \n",
    "    stopwords = set(corpus.stopwords.words('english'))\n",
    "    proc_sent = []\n",
    "    \n",
    "    for sent in split_sent:\n",
    "        # applies word tokenization \n",
    "        tokens = word_tokenize(sent.lower())\n",
    "\n",
    "         # apply lemmetaization on all words \n",
    "        lemma  = [wnl.lemmatize(t) for t in tokens]\n",
    "        \n",
    "        # remove stopewords from the predefined set of stopwords \n",
    "        re_st =  [l for l in lemma if l not in stopwords]\n",
    "\n",
    "        proc_sent.append(re_st)\n",
    "\n",
    "\n",
    "    return proc_sent\n",
    "\n",
    "proc_sent = process_paragraph('NLTK is a leading platform. for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries.')\n",
    "print(proc_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Algebra Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **describe briefly**\n",
    "\n",
    "1. **What is a vector?**  \n",
    "    A vector is a mathematical object used to describe both magnitude and direction. It is represented only by its magnitude and direction and is an element of a vector space.\n",
    "\n",
    "2. **What is a matrix?**  \n",
    "    A matrix is a rectangular array of numbers arranged in rows and columns. In the context of vectors, matrices are used to represent a collection of vectors and to perform linear transformations on vectors (e.g., rotation, scaling, shearing). \n",
    "    Matrices enable us to represent, manipulate, and transform vectors in multidimensional spaces.\n",
    "\n",
    "3. **What is the rank of a matrix?**  \n",
    "    The rank of a matrix represents the number of linearly independent vectors it contains. It includes both row rank and column rank, which are always equal. In the context of vectors and vector spaces, linearly independent vectors form a basis for the vector space, providing a minimal set of vectors to express any vector through linear combinations. \n",
    "    In machine learning, the rank of a matrix represents the number of dimensions (features) present in the data that provide useful information.\n",
    "\n",
    "4. **What is outer product expansion?**  \n",
    "    Outer product expansion involves taking each element of one vector and multiplying it by each element of another vector. The result is a matrix with dimensions determined by the lengths of the input vectors. When performed on matrices, it involves taking the outer product of the columns or rows of one matrix with the columns or rows of another matrix.\n",
    "\n",
    "5. **What is cosine similarity?**  \n",
    "    Cosine similarity is a mathematical method that is used to measure the similarity between vectors. In its essence, it is a normalized dot product, where the dot product is the projection of one vector onto another scaled by the lengths of the vectors and the cosine of the angle between them. The larger the dot product, the more aligned the vectors are with each other.\n",
    "\n",
    "    $$\n",
    "    a \\cdot b = \\|a\\| \\|b\\| \\cos(\\theta)\n",
    "    $$\n",
    "\n",
    "\n",
    "    However, this scale is highly influenced by the vectors' magnitudes. That's why cosine similarity is used, as it's normalized by the product of the vectors' norms, thus taking into account also the orientation between vectors.\n",
    "\"\n",
    "    $$\n",
    "    \\cos(\\theta) = \\frac{ a \\cdot b} { \\|a\\| \\|b\\|} \n",
    "    $$\n",
    "\n",
    "\n",
    "    In the context of NLP, cosine similarity is commonly used to measure the similarity between word embeddings, enabling tasks such as document similarity, information retrieval, and clustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Describe in a few sentences the concept of the gradient of a vector or matrix**\n",
    "\n",
    "The gradient of a vector or matrix extends the concept of the derivative to multivariable functions. It provides valuable information about the direction and rate of change of the function in each dimension of its input space. By computing the gradient, we can identify the direction in which the function increases most rapidly and use this information for optimization tasks, such as finding the minimum or maximum values of the function. In machine learning and optimization algorithms, the gradient plays a crucial role in guiding the search for optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explain briefly a linear classifier**\n",
    "A linear classifier is a machine learning method used in binary classification tasks, where it divides data points in the feature space depending on a decision boundary function. The decision boundary function is represented by the equation:\n",
    "\n",
    "$$\n",
    "c(x) = v^T x + v_0 \n",
    "$$\n",
    "\n",
    "Here,  $v$  is a vector containing weights for each feature in the input data. Each element represents the importance of the corresponding feature to the classification decision. It determines the orientation of the decision boundary in the feature space. While $V_0$ is a constant value added to the weighted sum of input features to shift the decision boundary in a linear classifier. It determines the position of the boundary in the feature space.\n",
    "\n",
    "This decision boundary splits the vector space into two parts depending on our label: $c_x = C_1$ if $ c(x) > 0 $ and $ c_x $ is a $ C_2 $ class label if $ c(x) < 0 $\n",
    "\n",
    "We can rephrase by simplifying equation in \\ref{eq:linear_classifier} by concatenating $ V_0 $ with $ V $ values:\n",
    "\n",
    "$$\n",
    "W^T = ([v_0,] \\circ v)^T\n",
    "$$\n",
    "\n",
    "And to compensate for this change, we also concatenate a vector of ones to the start of our input:\n",
    "\n",
    "$$\n",
    "X =  (1 \\circ x) \n",
    "$$\n",
    "From  the above Equations, we obtain:\n",
    "$$\n",
    "c(X) = W^T X \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Model Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three variable/features in predicting whether an email is spam or not: `Contacted`, `Colleague`, and `Neither`. Since `Neither` is the base level, it is not included as a separate variable.\n",
    "So,\n",
    "\n",
    "\\begin{equation}\n",
    "X =  [x_1, x_2]   \n",
    "\\end{equation}\n",
    "\n",
    "Logistic Regression Equation:\n",
    "\\begin{equation}\n",
    "ln(p/1-p) =  \\beta_0 + \\beta_1x_1 + \\beta_2x_2   \n",
    "\\end{equation}\n",
    "\n",
    "where,\n",
    "\n",
    "β₀ is the intercept\n",
    "\n",
    "β₁ is the coefficient for emails from colleague relative to the base level `Neither`\n",
    "\n",
    "β₂ is the coefficient for emails from contacted non-colleagues relative to the base level `Neither`\n",
    "\n",
    "We have the following three cases:\n",
    "\n",
    "1.   Colleague Case:\n",
    "\\begin{aligned}\n",
    "x_1 = 1\\\\\n",
    "x_2 = 0\n",
    "\\end{aligned}\n",
    "then\n",
    "\n",
    "\\begin{aligned}\n",
    "ln(p/1-p) =  \\beta_0 + \\beta_1(1) + \\beta_2(0)\\\\\n",
    "ln(p/1-p) =  \\beta_0 + \\beta_1\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "2.   Contacted Case:\n",
    "\\begin{aligned}\n",
    "x_1 = 0\\\\\n",
    "x_2 = 1\n",
    "\\end{aligned}\n",
    "then\n",
    "\n",
    "\\begin{aligned}\n",
    "ln(p/1-p) =  \\beta_0 + \\beta_1(0) + \\beta_2(1)\\\\\n",
    "ln(p/1-p) =  \\beta_0 + \\beta_2\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "3.  Neither case\n",
    "\\begin{aligned}\n",
    "x_1 = 0\\\\\n",
    "x_2 = 0\n",
    "\\end{aligned}\n",
    "then\n",
    "\n",
    "\\begin{aligned}\n",
    "ln(p/1-p) =  \\beta_0 + \\beta_1(0) + \\beta_2(0)\\\\\n",
    "ln(p/1-p) =  \\beta_0\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Calculating Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients:\n",
    "\\begin{equation}\n",
    "\\beta_0, \\beta_1, \\beta_2\n",
    "\\end{equation}\n",
    "\n",
    "The values of the parameters can be estimated using the Log-Likelihood, which we want to maximize:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "l(y, x, \\beta) =  \\sum_{i}^n y_ilnp_i - (1-y_i)ln(1-p_i)\n",
    "\\end{equation}\n",
    "\n",
    "Since the closed form solution for the logistic regression is not possible because the likelihood equations involve nonlinear functions of the parameters, we will use the numerical method to estimate the parameters. For this case, we will use the Newton-CG (conjugate gradient), an adaption/extension of the Newton-Raphson method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t    Coefficients: ['Intercept', 'Colleague', 'Contacted']\n",
      "Values of the Coefficients: [-0.6820826  -4.43119538 -2.090507  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Generate the df from the given frequency table\n",
    "# since neither is base the variable, it is added implicitly, i.e., for neither both colleague and contacted will be 0\n",
    "data = {\n",
    "    'Colleague': [1]*11 + [1]*1829 + [0]*98 + [0]*1568 + [0]*999 + [0]*1976,\n",
    "    'Contacted': [0]*11 + [0]*1829 + [1]*98 + [1]*1568 + [0]*999 + [0]*1976,\n",
    "    'Spam': [1]*11 + [0]*1829 + [1]*98 + [0]*1568 + [1]*999 + [0]*1976\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Intercept'] = 1\n",
    "\n",
    "#columns to be used / model parameters\n",
    "columns = ['Intercept', 'Colleague', 'Contacted']\n",
    "\n",
    "X = df[columns].values\n",
    "y = df['Spam'].values\n",
    "\n",
    "def logistic_function(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_likelihood(beta, X, y):\n",
    "    z = np.dot(X, beta)\n",
    "    return np.sum(y * np.log(logistic_function(z)) + (1 - y) * np.log(1 - logistic_function(z)))\n",
    "\n",
    "def gradient(beta, X, y):\n",
    "    z = np.dot(X, beta)\n",
    "    predictions = logistic_function(z)\n",
    "    return np.dot(X.T, y - predictions)\n",
    "\n",
    "# matrix of second derivates\n",
    "def hessian(beta, X, y):\n",
    "    z = np.dot(X, beta)\n",
    "    predictions = logistic_function(z)\n",
    "    weight_matrix = predictions * (1 - predictions)\n",
    "    return -np.dot(X.T, weight_matrix[:, np.newaxis] * X)\n",
    "\n",
    "# initial parameters estimates\n",
    "initial_params = np.zeros(X.shape[1])\n",
    "\n",
    "# Optimize by maximizing the log likelihood\n",
    "output = minimize(fun=lambda beta, X, y: -log_likelihood(beta, X, y),\n",
    "                  x0=initial_params,\n",
    "                  args=(X, y),\n",
    "                  method='Newton-CG',\n",
    "                  jac=lambda beta, X, y: -gradient(beta, X, y),\n",
    "                  hess=lambda beta, X, y: hessian(beta, X, y))\n",
    "print(\"\\t    Coefficients:\", [\"Intercept\", \"Colleague\", \"Contacted\"])\n",
    "print(\"Values of the Coefficients:\", output.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6481,\n  \"fields\": [\n    {\n      \"column\": \"Colleague\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Contacted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Spam\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-683a694b-1f91-471e-b37b-66e5aafb389d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colleague</th>\n",
       "      <th>Contacted</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-683a694b-1f91-471e-b37b-66e5aafb389d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-683a694b-1f91-471e-b37b-66e5aafb389d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-683a694b-1f91-471e-b37b-66e5aafb389d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-c438f434-7376-47e3-ade1-8319552260bc\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c438f434-7376-47e3-ade1-8319552260bc')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-c438f434-7376-47e3-ade1-8319552260bc button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   Colleague  Contacted  Spam\n",
       "0          1          0     1\n",
       "1          1          0     1\n",
       "2          1          0     1\n",
       "3          1          0     1\n",
       "4          1          0     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the df from the given frequency table\n",
    "# since neither is base the variable, it is added implicitly, i.e., for neither both colleague and contacted will be 0\n",
    "data = {\n",
    "    'Colleague': [1]*11 + [1]*1829 + [0]*98 + [0]*1568 + [0]*999 + [0]*1976,\n",
    "    'Contacted': [0]*11 + [0]*1829 + [1]*98 + [1]*1568 + [0]*999 + [0]*1976,\n",
    "    'Spam': [1]*11 + [0]*1829 + [1]*98 + [0]*1568 + [1]*999 + [0]*1976\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Colleague', 'Contacted']]\n",
    "y = df['Spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Coefficient\n",
      "Colleague    -4.103004\n",
      "Contacted    -2.059136\n",
      "Intercept    -0.691370\n"
     ]
    }
   ],
   "source": [
    "# get the coefficients\n",
    "coefficients = model.coef_[0]\n",
    "intercept = model.intercept_[0]\n",
    "feature_names = ['Colleague', 'Contacted']\n",
    "coef_df = pd.DataFrame(coefficients, index=feature_names, columns=['Coefficient'])\n",
    "coef_df.loc['Intercept'] = intercept\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a minor difference observed between the values of the coefficients calculated using both the methods, which can be primarily attributed to the fact that one, a different method is being used, and second, L2 regularization is being used in the sklearn implementation. As a background work, we also tried turning off the L2 regularization, which actually resulted in the values of coefficients being almost identical for both methods. Moreover, the convergence criteria for both methods can also affect the final values of the coefficients, such as the tolerance or the maximum number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Non-Spam', 'Spam'], columns=['Predicted Non-Spam', 'Predicted Spam'])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**: number of correct predictions (both true positives and true negatives) from the total predictions. A high accuracy doesn't always mean that the model is performing well. It is important to look at other metrics especially if the classes are imbalanced. We get an accuracy of around 82%, but we also have the class imbalance issue. So, this might not be representative.\n",
    "\n",
    "\\begin{equation}\n",
    "Accuracy= (TP+TN+FP+FN) / (TP+TN)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "**Recall**: how many of the actual positives are correctly identified. Our model has a recall of 0 since it predicts the negative class (non-spam) in all the cases (TP is zero).\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "Recall = (TP) / (TP+FN)\n",
    "\\end{equation}\n",
    "\n",
    "**Precision**: how many of the predictions are actually correct. Our model has also a precision of 0 since it predicts the negative class (non-spam) in all the cases.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "Precision = (TP) / (TP+FP)\n",
    "\\end{equation}\n",
    "\n",
    "**F1 Score**: The harmonic mean of Precision and Recall, providing a balance between the two in cases where one may be significantly higher than the other. 0 since precision and recall is 0.\n",
    "\n",
    "\\begin{equation}\n",
    "F1 = 2(precision * recall ) / (precision+recall)\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8290387285912668\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred, zero_division=0)\n",
    "precision = precision_score(y, y_pred, zero_division=0)\n",
    "f1 = f1_score(y, y_pred, zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Trustworthiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7700539735715615\n",
      "Recall: 0.9078726968174204\n",
      "Precision: 0.711701196381675\n",
      "F1 Score: 0.7979062730023717\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_res, y_res)\n",
    "y_pred_res = model.predict(X_res)\n",
    "\n",
    "accuracy_res = accuracy_score(y_res, y_pred_res)\n",
    "recall_res = recall_score(y_res, y_pred_res)\n",
    "precision_res = precision_score(y_res, y_pred_res)\n",
    "f1_res = f1_score(y_res, y_pred_res)\n",
    "print(\"Accuracy:\", accuracy_res)\n",
    "print(\"Recall:\", recall_res)\n",
    "print(\"Precision:\", precision_res)\n",
    "print(\"F1 Score:\", f1_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the frequency table, it can be easily observed that the data is imbalanced, i.e., around 5000 from the not-spam class and only 1100 from the spam class. This issue gets reflected in the above trained logistic regression model.\n",
    "\n",
    "If we just look at the accuracy of the model (>80%), the model looks quite decent and trustworthy, which is quite misleading at the first sight. Upon looking into more details such as confusion matrix, it can be seen that the model is heavily biased towards the non-spam class. In fact, it classifies each sample as a non-spam, but due to the imbalance, we nevertheless get a very high accuracy.\n",
    "\n",
    "In reality, the model is not trustworthy and fails to predict the email as spam or not. This could be because regression models rely on the mean and standard deviation. When dealing with skewed data, the mean can be deceptive as the most frequent values in the distribution might not align closely with the mean.\n",
    "\n",
    "Moreover, the given data only checks the sender of the email, i.e., whether it has been sent by colleague, previously contacted person, or neither. It doesn't look into the content of the email, for example, use of certain words, incorrect grammar etc.\n",
    "\n",
    "\n",
    "**Possible Solutions**\n",
    "\n",
    "The model can be improved by addressing the class imbalance issue. For example, oversampling of the minority class using SMOTE (Synthetic Minority Oversampling Technique). This was done as an extra work and it can be observed that the model now performs better by not identifying all samples as non-spam. Another solution could be lowering the threshold from the default 0.5 to classify positive/negative samples. However, this could increase false positives.\n",
    "\n",
    "**Strengths & Weaknesses**\n",
    "\n",
    "While the approach certainly has multiple strengths like being very easy to implement and interpret, and also providing a probabilistic outcome which can be quite helpful in thresholding, it clearly lacks the complexity to provide decent results when there are issues like class imbalance. Being able to produce decent results despite class imbalance is important because in most of the practical use cases, class imbalance is present. Moreover, it can be quite prone to overfitting, as was the case in this use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.TF-IDF\n",
    " TF-IDF stands for The Term Frequency-Inverse Document Frequency is a statistical method that is used to process textual-data that measures how important a word is in a set of documents where it's a scaled down version of bag of words,  it's the result of multiplying of two terms\n",
    "**Term frequency(TF)**, which measures the frequency of words that appeared in a document ,however to address the variation in document lengths, word frequency is often normalized by the total document length, ensuring fair comparison across documents regardless of their size.\n",
    "$$\n",
    "tf_{term} = \\frac{number of times a term appears in a documnet}{totall number of terms in the document } \n",
    "$$\n",
    "**Inverse document frequency($IDF$)**, that measures the importance of a word across the entire document collection, where it assigns lower weight to frequent words and assigns greater weight for the words that are infrequent. thus reducing the influence of common words and highlighting the importance of rare ones \n",
    "$$\n",
    "IDF_{term} = \\log (\\frac{totall numebr of documnets}{number of documents containing the term }) \n",
    "$$\n",
    "by multiplying both terms $Tf$ and $IDF$ :\n",
    "$$\n",
    "\\textit{TF-IDF}_{term,document} = TF_{term,document} * IDF_{term,document}  \n",
    "$$\n",
    "yielding a score that enables the identification of terms that are both frequently occurring within a document and relatively rare across the entire document collection.[3]\n",
    "\n",
    "The TF-IDF approach typically provides a more nuanced and informative representation of text data compared to BOW approach, particularly in tasks requiring document similarity analysis. as BOW assigns equal importance to all terms, which leads to common words taking over the representation and less informative terms being ignored. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classifying movie reviews using textual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Ensure the required NLTK resources are available\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the IMDb dataset\n",
    "url = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "dataset_path = \"/content/aclImdb_v1.tar.gz\"\n",
    "urllib.request.urlretrieve(url, dataset_path)\n",
    "\n",
    "with tarfile.open(dataset_path) as tar:\n",
    "    tar.extractall(path=\"/content/\")\n",
    "\n",
    "# Function to read data from the extracted files\n",
    "def read_imdb_data(data_dir='/content/aclImdb'):\n",
    "    data = {'train': {}, 'test': {}}\n",
    "    labels = {'train': {}, 'test': {}}\n",
    "\n",
    "    for data_type in ['train', 'test']:\n",
    "        for sentiment in ['pos', 'neg']:\n",
    "            path = os.path.join(data_dir, data_type, sentiment)\n",
    "            reviews = []\n",
    "            sentiment_labels = []\n",
    "\n",
    "            for file_name in os.listdir(path):\n",
    "                with open(os.path.join(path, file_name), 'r', encoding='utf-8') as file:\n",
    "                    reviews.append(file.read())\n",
    "                    sentiment_labels.append(1 if sentiment == 'pos' else 0)\n",
    "\n",
    "            data[data_type][sentiment] = pd.DataFrame({\n",
    "                'review': reviews,\n",
    "                'sentiment': sentiment_labels\n",
    "            })\n",
    "\n",
    "        data[data_type] = pd.concat([data[data_type]['pos'], data[data_type]['neg']], ignore_index=True)\n",
    "\n",
    "    return data['train'], data['test']\n",
    "\n",
    "train_data, test_data = read_imdb_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and not word in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "train_data['review'] = train_data['review'].apply(preprocess)\n",
    "test_data['review'] = test_data['review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_data['review'])\n",
    "X_train_bow = bow_vectorizer.fit_transform(train_data['review'])\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_data['review'])\n",
    "X_test_bow = bow_vectorizer.transform(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train logistic regression models\n",
    "model_tfidf = LogisticRegression(max_iter=1000)\n",
    "model_bow = LogisticRegression(max_iter=1000)\n",
    "\n",
    "model_tfidf.fit(X_train_tfidf, train_data['sentiment'])\n",
    "model_bow.fit(X_train_bow, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with TF-IDF: 0.88228\n",
      "Accuracy with BoW: 0.86164\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and evaluate the models\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "y_pred_bow = model_bow.predict(X_test_bow)\n",
    "\n",
    "accuracy_tfidf = accuracy_score(test_data['sentiment'], y_pred_tfidf)\n",
    "accuracy_bow = accuracy_score(test_data['sentiment'], y_pred_bow)\n",
    "\n",
    "print(\"Accuracy with TF-IDF:\", accuracy_tfidf)\n",
    "print(\"Accuracy with BoW:\", accuracy_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with KNN (k=3) using TF-IDF: 0.62864\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate a KNN classifier\n",
    "knn_tfidf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_tfidf.fit(X_train_tfidf, train_data['sentiment'])\n",
    "y_pred_knn_tfidf = knn_tfidf.predict(X_test_tfidf)\n",
    "accuracy_knn_tfidf = accuracy_score(test_data['sentiment'], y_pred_knn_tfidf)\n",
    "\n",
    "print(\"Accuracy with KNN (k=3) using TF-IDF:\", accuracy_knn_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] Christine P. Chai. Comparison of text preprocessing methods. Natural\n",
    "Language Engineering, 29(3):509ˆa553, 2023. <br><br>\n",
    "[2] Alebachew Chiche and Betselot Yitagesu. Part of speech tagging: a system-\n",
    "atic review of deep learning and machine learning approaches. Journal of\n",
    "Big Data, 9(1):10, Jan 2022.<br><br>\n",
    "[3] Shahzad Qaiser and Ramsha Ali. Text mining: Use of tf-idf to examine\n",
    "the relevance of words to documents. International Journal of Computer\n",
    "Applications, 181, 07 2018.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
