{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "themodel:\n",
      "demo(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "models parameters\n",
      "Parameter containing:\n",
      "tensor([[-0.0201,  0.0739,  0.0990,  ..., -0.0211, -0.0580,  0.0933],\n",
      "        [ 0.0789,  0.0578,  0.0324,  ..., -0.0754,  0.0539, -0.0089],\n",
      "        [-0.0404,  0.0532,  0.0965,  ...,  0.0786,  0.0105, -0.0747],\n",
      "        ...,\n",
      "        [ 0.0752, -0.0989, -0.0302,  ..., -0.0231,  0.0799, -0.0597],\n",
      "        [-0.0449, -0.0532, -0.0422,  ...,  0.0811,  0.0705,  0.0476],\n",
      "        [-0.0027,  0.0256, -0.0097,  ...,  0.0447, -0.0973, -0.0157]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0902,  0.0946, -0.0971, -0.0408, -0.0149, -0.0837,  0.0629, -0.0108,\n",
      "         0.0325,  0.0806,  0.0027, -0.0493, -0.0018,  0.0026, -0.0935,  0.0492,\n",
      "         0.0301,  0.0335,  0.0074,  0.0376,  0.0958,  0.0742,  0.0048,  0.0883,\n",
      "        -0.0364, -0.0149,  0.0424, -0.0395, -0.0966, -0.0548,  0.0876,  0.0595,\n",
      "         0.0041, -0.0808,  0.0245,  0.0627, -0.0474,  0.0212, -0.0512,  0.0233,\n",
      "         0.0976,  0.0726,  0.0192,  0.0261,  0.0643, -0.0800,  0.0342,  0.0836,\n",
      "        -0.0053,  0.0598, -0.0043,  0.0196,  0.0213,  0.0464, -0.0703,  0.0550,\n",
      "        -0.0683, -0.0169,  0.0347, -0.0058, -0.0914,  0.0458, -0.0163,  0.0165,\n",
      "         0.0179,  0.0069, -0.0447,  0.0125,  0.0562,  0.0856, -0.0202, -0.0124,\n",
      "         0.0143, -0.0585,  0.0452, -0.0736,  0.0512,  0.0524, -0.0023, -0.0328,\n",
      "        -0.0114, -0.0768,  0.0259,  0.0617,  0.0737,  0.0400,  0.0970,  0.0100,\n",
      "        -0.0932, -0.0386, -0.0420,  0.0445,  0.0693, -0.0256,  0.0434,  0.0090,\n",
      "         0.0005,  0.0935,  0.0261, -0.0740,  0.0903,  0.0543,  0.0257, -0.0459,\n",
      "         0.0881,  0.0167, -0.0777,  0.0727,  0.0494, -0.0529,  0.0269,  0.0631,\n",
      "         0.0313,  0.0115, -0.0240,  0.0686,  0.0730, -0.0127, -0.0397, -0.0544,\n",
      "         0.0747,  0.0127, -0.0852,  0.0448, -0.0592,  0.0224,  0.0681, -0.0464,\n",
      "         0.0741,  0.0284, -0.0201, -0.0127, -0.0696,  0.0317, -0.0359, -0.0191,\n",
      "        -0.0921, -0.0700,  0.0839, -0.0691,  0.0438,  0.0640,  0.0524, -0.0296,\n",
      "         0.0530, -0.0659, -0.0314,  0.0518,  0.0722, -0.0566,  0.0553, -0.0319,\n",
      "        -0.0233,  0.0854,  0.0487, -0.0634, -0.0978, -0.0229,  0.0539,  0.0815,\n",
      "        -0.0544,  0.0424,  0.0021, -0.0875, -0.0155, -0.0596,  0.0652,  0.0447,\n",
      "        -0.0644, -0.0146,  0.0714,  0.0728, -0.0633,  0.0086,  0.0040,  0.0276,\n",
      "        -0.0056, -0.0713, -0.0650,  0.0946, -0.0676,  0.0654,  0.0599,  0.0028,\n",
      "        -0.0265, -0.0827, -0.0636,  0.0022, -0.0210,  0.0331,  0.0438, -0.0291,\n",
      "        -0.0872, -0.0473, -0.0046, -0.0431,  0.0721, -0.0885,  0.0131, -0.0638],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0487,  0.0524, -0.0354,  ...,  0.0604, -0.0065,  0.0212],\n",
      "        [ 0.0359, -0.0096, -0.0154,  ..., -0.0121,  0.0459,  0.0401],\n",
      "        [ 0.0231,  0.0294,  0.0572,  ..., -0.0156,  0.0501, -0.0309],\n",
      "        ...,\n",
      "        [-0.0479,  0.0406,  0.0109,  ...,  0.0550,  0.0105, -0.0695],\n",
      "        [ 0.0371, -0.0656, -0.0459,  ..., -0.0662,  0.0202,  0.0597],\n",
      "        [ 0.0264,  0.0307, -0.0253,  ..., -0.0680,  0.0521, -0.0180]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0586,  0.0081,  0.0045, -0.0313, -0.0457,  0.0174,  0.0646,  0.0303,\n",
      "        -0.0140, -0.0620], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "'''This shows the fundamental structure of a PyTorch model: \n",
    "there is an __init__() method that defines the layers and other components of a model,\n",
    " and a forward() method where the computation gets done.\n",
    " Note that we can print the model, or any of its submodules, to learn about its structure.'''\n",
    "\n",
    "import torch \n",
    "\n",
    "class demo(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(demo,self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100,200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200,10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x \n",
    "    \n",
    "demo = demo()\n",
    "\n",
    "print(\"themodel:\")\n",
    "print(demo)\n",
    "\n",
    "print(demo.linear2)\n",
    "\n",
    "print(\"models parameters\")\n",
    "for param in demo.parameters():\n",
    "    print(param)\n",
    "\n",
    "# To train a model, we need a loss function and an optimizer.\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(demo.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:44<00:00, 594996.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 455297.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:06<00:00, 696158.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 2544758.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Working with data PyTorch has two primitives to work with data: torch.utils.data.DataLoader and torch.utils.data.Dataset.\n",
    " Dataset stores the samples and their corresponding labels,\n",
    " DataLoader wraps an iterable around the Dataset.'''\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X [N,C,H,W]: torch.Size([64, 1, 28, 28])\n",
      "shape of y :torch.Size([64])torch.int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"We pass the Dataset as an argument to DataLoader. This wraps an iterable over our dataset, and supports automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element in the dataloader iterable will return a batch of 64 features and labels.\"\"\"\n",
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "batch_size = 64 \n",
    "\n",
    "#create dataset \n",
    "train_dataloader = DataLoader(training_data,batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "for X,y in test_dataloader:\n",
    "    print(f\"shape of X [N,C,H,W]: {X.shape}\")\n",
    "    print(f\"shape of y :{y.shape}{y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetworkz(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#  define a model \n",
    "class NeuralNetworkz(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        # The nn.Flatten() layer in your neural network model serves to transform the multi-dimensional input tensor into a one-dimensional tensor, \n",
    "        # which is necessary for the subsequent fully connected (nn.Linear) layers to process the data correctly.\n",
    "        self.linear_relu_stack = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28*28,512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512,512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512,10)\n",
    "        )\n",
    "    def forward (self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "model = NeuralNetworkz()\n",
    "print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (dataloader,model,loss_fn,optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch ,(X,y) in enumerate (dataloader):\n",
    "        # prediction error \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation \n",
    "        loss.backward() # --> calculates the gradients\n",
    "        \"\"\"Essentially, it performs the backward pass, calculating the gradients of the loss function concerning each parameter.\n",
    "          These gradients are stored in the .grad attribute of each parameter.\"\"\"\n",
    "        optimizer.step() # --> update model parameters\n",
    "        \"\"\"The optimizer (e.g., SGD, Adam) uses these gradients to adjust the parameters in an attempt to minimize the loss.\n",
    "          The specific update rule depends on the type of optimizer being used.\"\"\"\n",
    "        optimizer.zero_grad() # reset gradient to zero \n",
    "        \"\"\"It resets the gradients of all the model parameters before the next iteration of the training loop.\n",
    "          This is important because by default, PyTorch accumulates gradients, which means that without resetting them, \n",
    "          you would sum gradients from multiple backward passes.\"\"\"\n",
    "\n",
    "        if batch % 100 ==0:\n",
    "            load,current = loss.item(), (batch+1) * len(X)\n",
    "            print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "        \"\"\"This checks if the current batch number (batch) is a multiple of 100. \n",
    "        This condition ensures that the following logging code is executed only every 100 batches.\"\"\"\n",
    "\n",
    "        \"\"\"current = (batch + 1) * len(X):\n",
    "            This calculates the current position in the dataset. batch + 1 gives the 1-based index of the current batch. \n",
    "            len(X) gives the number of samples in the current batch. \n",
    "            Multiplying these gives the number of samples processed so far.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataLoader, model,loss_fn):\n",
    "    size = len(dataLoader.dataset)\n",
    "    num_batches = len(dataLoader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataLoader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches \n",
    "        correct /= size \n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss:2.316178 [   64/60000]\n",
      "loss:2.298798 [ 6464/60000]\n",
      "loss:2.281172 [12864/60000]\n",
      "loss:2.274479 [19264/60000]\n",
      "loss:2.254983 [25664/60000]\n",
      "loss:2.224504 [32064/60000]\n",
      "loss:2.235098 [38464/60000]\n",
      "loss:2.201839 [44864/60000]\n",
      "loss:2.203588 [51264/60000]\n",
      "loss:2.164916 [57664/60000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:2.177467 [   64/60000]\n",
      "loss:2.160147 [ 6464/60000]\n",
      "loss:2.103653 [12864/60000]\n",
      "loss:2.120132 [19264/60000]\n",
      "loss:2.059521 [25664/60000]\n",
      "loss:1.998471 [32064/60000]\n",
      "loss:2.030839 [38464/60000]\n",
      "loss:1.950675 [44864/60000]\n",
      "loss:1.966025 [51264/60000]\n",
      "loss:1.873186 [57664/60000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:1.922543 [   64/60000]\n",
      "loss:1.881085 [ 6464/60000]\n",
      "loss:1.767598 [12864/60000]\n",
      "loss:1.811052 [19264/60000]\n",
      "loss:1.691028 [25664/60000]\n",
      "loss:1.640318 [32064/60000]\n",
      "loss:1.673149 [38464/60000]\n",
      "loss:1.574811 [44864/60000]\n",
      "loss:1.606375 [51264/60000]\n",
      "loss:1.491665 [57664/60000]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:1.591628 [   64/60000]\n",
      "loss:1.548015 [ 6464/60000]\n",
      "loss:1.403671 [12864/60000]\n",
      "loss:1.473656 [19264/60000]\n",
      "loss:1.352060 [25664/60000]\n",
      "loss:1.345770 [32064/60000]\n",
      "loss:1.366471 [38464/60000]\n",
      "loss:1.293192 [44864/60000]\n",
      "loss:1.326705 [51264/60000]\n",
      "loss:1.227970 [57664/60000]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:1.336727 [   64/60000]\n",
      "loss:1.311797 [ 6464/60000]\n",
      "loss:1.149315 [12864/60000]\n",
      "loss:1.252359 [19264/60000]\n",
      "loss:1.125902 [25664/60000]\n",
      "loss:1.147217 [32064/60000]\n",
      "loss:1.173358 [38464/60000]\n",
      "loss:1.113785 [44864/60000]\n",
      "loss:1.150281 [51264/60000]\n",
      "loss:1.067188 [57664/60000]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    # test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "# to save the internal parameters of the model \n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-creating the model structure and loading the state dictionary into it.\n",
    "model = NeuralNetworkz()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
